# Clothing-classifier

## Overview

Project to build a segmentation pipeline and attribution extraction capabilities

## Segmentation(SAM2+CLIP_segmentation_pipe.ipynb)

I have implemented a SAM2+CLIP pipeline for the segmentation task 
Explanation : SAM2 provides state of the art results on point-based and box-based guided prompting  segmentation. CLIP is added as a visual-language model to further classify the most appropriate mask generated by the SAM2 model using itâ€™s state-of-the-art image-text retrieval capabilities. 
## Sleeve attribute classification for upper-wear garments(CLIP_sleeves_classification_pipeline.ipynb)

Used the OpenAI CLIP model for the task considering its high image-text retrieval accuracy, and the model gives correct results for all input images tried for the 3 labels - Sleeveless, short-sleeve, and long-sleeve with good confidence. The model gives much higher accuracy when the input images are passed without segmentation because the model gets full context surrounding the clothing with arms, hands, etc. which is essential to classify the sleeve type. 

## Garment type, colour and design pattern classification 

I have used the BLIP-2 model for the task leveraging its natural language prompt-based visual question answering capabilities. The model gives the correct results for the garment type and dominant colour for all input images. The model gives highly fine-grained and accurate design patterns for the inputs, but gives an empty response in a few cases. 
