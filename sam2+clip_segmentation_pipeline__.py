# -*- coding: utf-8 -*-
"""SAM2+CLIP_segmentation_pipeline__.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14NpcMJBgLzEGknKkl77wo_oEqaJQSzEi
"""

import os
import numpy as np
import torch
import torchvision
import sys
import matplotlib.pyplot as plt
from PIL import Image

import cv2

if torch.cuda.is_available():
    device = torch.device("cuda")
print(f"using device: {device}")



!{sys.executable} -m pip install opencv-python matplotlib

!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/sam2.git'

!mkdir -p ../checkpoints/
!wget -P ../checkpoints/ https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt

from sam2.build_sam import build_sam2
from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator

sam2_checkpoint = "../checkpoints/sam2.1_hiera_large.pt"
model_cfg = "configs/sam2.1/sam2.1_hiera_l.yaml"

sam2 = build_sam2(model_cfg, sam2_checkpoint, device=device, apply_postprocessing=False)

mask_generator = SAM2AutomaticMaskGenerator(sam2)

from sam2.sam2_image_predictor import SAM2ImagePredictor
predictor = SAM2ImagePredictor(sam2)

!pip install git+https://github.com/openai/CLIP.git

import clip

# Load CLIP
clip_model, clip_preprocess  = clip.load("ViT-B/32", device=device)
clip_model.eval()

np.random.seed(3)

def show_anns(anns, borders=True):
    if len(anns) == 0:
        return
    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)
    ax = plt.gca()
    ax.set_autoscale_on(False)

    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))
    img[:, :, 3] = 0
    for ann in sorted_anns:
        m = ann['segmentation']
        color_mask = np.concatenate([np.random.random(3), [0.5]])
        img[m] = color_mask
        if borders:
            import cv2
            contours, _ = cv2.findContours(m.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
            # Try to smooth contours
            contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]
            cv2.drawContours(img, contours, -1, (0, 0, 1, 0.4), thickness=1)

    ax.imshow(img)

def show_points(coords, labels, ax, marker_size=375):
    pos_points = coords[labels==1]
    neg_points = coords[labels==0]
    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)
    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)

def show_mask(mask, ax, random_color=False, borders = True):
    if random_color:
        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)
    else:
        color = np.array([30/255, 144/255, 255/255, 0.6])
    h, w = mask.shape[-2:]
    mask = mask.astype(np.uint8)
    mask_image =  mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
    if borders:
        import cv2
        contours, _ = cv2.findContours(mask,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
        # Try to smooth contours
        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]
        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2)
    ax.imshow(mask_image)

def show_masks(image, masks, scores, point_coords=None, box_coords=None, input_labels=None, borders=True):
    for i, (mask, score) in enumerate(zip(masks, scores)):
        plt.figure(figsize=(10, 10))
        plt.imshow(image)
        show_mask(mask, plt.gca(), borders=borders)
        if point_coords is not None:
            assert input_labels is not None
            show_points(point_coords, input_labels, plt.gca())
        if box_coords is not None:
            # boxes
            show_box(box_coords, plt.gca())
        if len(scores) > 1:
            plt.title(f"Mask {i+1}, Score: {score:.3f}", fontsize=18)
        plt.axis('off')
        plt.show()

def visualize_all_sam_masks(image_rgb, masks):
    plt.figure(figsize=(15, 5))
    for i, mask in enumerate(masks):
        overlay = image_rgb.copy()
        overlay[mask['segmentation']] = [0, 255, 0]  # green highlight
        mask_area = mask['segmentation'].sum()
        iou = mask['predicted_iou']
        print(f"Mask {i + 1} Area: {mask_area}")
        print(f"Mask {i + 1} Iou:{iou}")
        plt.figure(figsize=(10, 10))
        plt.imshow(overlay)
        plt.axis("off")
        plt.show()
    plt.suptitle("Overlay of SAM Masks")
    plt.tight_layout()
    plt.show()

def get_top_n_masks_by_area(masks, n=2):
    areas = np.array([np.sum(mask) for mask in masks])
    top_indices = np.argsort(areas)[-n:][::-1]
    return masks[top_indices], top_indices, areas[top_indices]

def segment_image_SAM2(image_path: str, show_visualization: bool = True):
    # Load image
    image = Image.open(image_path)
    image = np.array(image.convert("RGB"))

    # Run segmentation
    masks = mask_generator.generate(image)
    print(f"Number of masks generated: {len(masks)}")

    plt.figure(figsize=(8, 8))
    plt.imshow(image)
    show_anns(masks)
    plt.axis('off')
    plt.show()


    if show_visualization:
      visualize_all_sam_masks(image, masks)

    return masks

def segment_upper_wear(image_path: str, visualize=True):
    # Load image
    image = Image.open(image_path)
    image = np.array(image.convert("RGB"))

    height, width, _ = image.shape
    print(f"Image size: {width}x{height}")


    # point based prompting to direct the model
    input_points = np.array([[width//2, height//2], [width//2 + 20, height//2  ],[width//2 - 20, height//2], [5,5], [width-5,height-5]])
    #postive and negative(mask background) point labelling
    input_labels = np.array([1,1,1,0,0])

    # Run SAM-2 segmentation

    predictor.set_image(image)

    #plotting positive and negative SAM-2 prompt points
    plt.figure(figsize=(10, 10))
    plt.imshow(image)
    show_points(input_points, input_labels, plt.gca())
    plt.axis('on')
    plt.show()

    masks, scores, logits = predictor.predict(
    point_coords=input_points,
    point_labels=input_labels,
    multimask_output=True)

    print(f"Number of masks generated using SAM-2: {len(masks)}")
    show_masks(image, masks, scores, point_coords=input_points, input_labels=input_labels, borders=True)
    # getting top2 masks with highest area
    print(f"getting top-2 masks with the highest area")
    masks_2, indices, areas = get_top_n_masks_by_area(masks, n=2)

    # Encoding the prompts for CLIP


    prompt_inputs = clip.tokenize([
    "Upper clothing garment and no human face",
    "Human face"
       ]).to(device)

    #text_inputs = clip.tokenize(label).to(device)
    #text_inputs2 = clip.tokenize(prompt2).to(device)

    with torch.no_grad():
     text_feature = clip_model.encode_text(prompt_inputs)

     #text_feature2 = clip_model.encode_text(text_inputs2)


    text_feature /= text_feature.norm(dim=-1, keepdim=True)


    best_mask = None
    best_score = -1



    for m in masks_2:
       segmentation = m
       x, y, w, h = cv2.boundingRect(segmentation.astype(np.uint8))
       segmentation = segmentation.astype(bool)
       masked_img = image.copy()
       masked_img[~segmentation] = 0
       cropped = masked_img[y:y+h, x:x+w]

       if cropped.size == 0:
          continue

       cropped_pil = Image.fromarray(cropped)
       cropped_clip = clip_preprocess(cropped_pil).unsqueeze(0).to(device)

       print(f"Mask area = {segmentation.sum()}")
       print(f"Mask area% = {segmentation.sum()/(height*width)}")
       # Display the cropped image
       plt.figure(figsize=(5, 5))
       plt.imshow(cropped)
       plt.title(f"Cropped segment")
       plt.axis('off')
       plt.show()

       with torch.no_grad():
         image_feature = clip_model.encode_image(cropped_clip)

       image_feature /= image_feature.norm(dim=-1, keepdim=True)

      # Compute similarities for the 2 prompts
       similarities = (image_feature @ text_feature.T).squeeze(0)


       print(similarities)
       sim = similarities[0].item()
       #print(f"similarity to face {similarities[1].item()}")
       #overall_similarity = sim - 0.3*similarities[1].item()
       #print(f"overall similarity {overall_similarity}")

       if sim > best_score:
         best_score = sim
         best_mask = segmentation

    print("Final mask result - ")
    # Visualize result
    if visualize and best_mask is not None:

       overlay = image.copy()
       overlay[best_mask] = [0, 255, 0]  # green highlight

       plt.figure(figsize=(10, 10))
       plt.imshow(overlay)
       plt.title(f"Best Match Score: {best_score:.2f}")
       plt.axis("off")
       plt.show()
    else:
       print("No upper wear mask found.")

    #returning best mask
    return best_mask



segment_upper_wear('/content/image_ex.jpg')

segment_upper_wear('/content/clothing_image.jpg')

segment_upper_wear('/content/upper-garment.webp')

segment_upper_wear('/content/AW23_BlogUpdate_4WaysToWearAVNeck_FeatureImage.webp')



segment_upper_wear('/content/Upper_man.jpg')

segment_upper_wear('/content/working-women-clothes-in-wardrobe.jpg')

segment_upper_wear('/content/bf5314fa-1208-4c4c-9945-9af4452ddc431662728283802-Computerised-Cable-Knit-Pattern-Sweater-291662728283275-1.jpg')

segment_upper_wear('/content/1000_F_268274753_wxfR4uQN5wUbQxlrHqJeZA3CiKtN8vlu.jpg')

segment_upper_wear('/content/c9e205b6-2356-4682-928c-deb94571ca8d1728372662389-High-Star-Men-Windcheater-Tailored-Jacket-1781728372661775-1.jpg')

segment_upper_wear('/content/43956Black-yellow40_1_7.webp')

segment_upper_wear('/content/tropical-floral-printed-party-wear-half-shirt-men-s-plus-size-guniaa-fashions-3.webp')

segment_upper_wear('/content/2_1ddf0b20-3e6d-471c-b4c0-ae96729df9ba.webp')

segment_upper_wear('/content/CSMSSRT6078_1_ad9219ef-869d-44b2-9dd2-5876b06cc708.webp')

segment_upper_wear('/content/crislonsblack_600x600_crop_center.webp')

segment_upper_wear('/content/ss-24_4000x5000-04-10-24_93_style_mfs-14973-s-16-blue_2_mfs-14973-s-16-blue.webp')

segment_upper_wear('/content/c590fb1e-6c50-4b79-afb4-e8a6f022cd221692266645876-United-Colors-of-Benetton-Men-Tshirts-5691692266645451-1.jpg')

segment_upper_wear('/content/MSH-1538.jpg')

segment_upper_wear('/content/61LyNGXs01L._AC_UY1100_.jpg')

segment_upper_wear('/content/pyre-mens-shirt-dark-red1.webp')

segment_upper_wear('/content/71nWEGLO0vL._AC_UY1100_.jpg')